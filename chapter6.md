# 第6章：感知算法演进

## 本章概述

自动驾驶感知算法是整个系统的"眼睛"，负责理解车辆周围环境。从2016年深度学习引入以来，感知算法经历了从2D到3D、从单帧到时序、从局部到全局的多次范式革命。本章将深入剖析这一演进过程的技术细节、关键突破和工程落地挑战。

## 6.1 从2D检测到3D感知 (2016-2020)

### 6.1.1 深度学习之前的传统方法

在深度学习革命之前，自动驾驶感知主要依赖传统计算机视觉方法：

**特征工程时代的核心技术栈：**
```
传统感知流水线 (Pre-2016)
┌─────────────┐    ┌──────────────┐    ┌───────────┐
│  图像预处理  │ -> │  特征提取     │ -> │  分类器   │
│  - 去噪      │    │  - HOG       │    │  - SVM    │
│  - 增强      │    │  - SIFT/SURF │    │  - AdaBoost│
│  - 边缘检测  │    │  - Haar      │    │  - RF     │
└─────────────┘    └──────────────┘    └───────────┘
```

**MobileEye早期方案 (EyeQ1-3时代)：**
- 基于模板匹配的车辆检测
- Haar特征级联分类器检测行人
- 基于Hough变换的车道线检测
- 光流法进行运动目标跟踪
- 立体视觉深度估计（双目方案）

**传统方法的致命缺陷：**
1. **泛化能力差**：手工特征无法覆盖复杂场景
2. **计算效率低**：滑动窗口遍历计算量巨大
3. **精度瓶颈**：检测率难以突破90%
4. **工程复杂度高**：需要大量规则和参数调优

### 6.1.2 2D检测的统治时代 (2016-2018)

2016年是自动驾驶感知的分水岭，深度学习开始全面接管：

**里程碑事件：**
- 2016.1: YOLO论文发表，实时目标检测成为可能
- 2016.5: NVIDIA发布DAVE-2，展示端到端驾驶可行性
- 2016.10: Tesla宣布所有新车配备Autopilot 2.0硬件

**主流2D检测架构对比：**

| 算法 | 速度(FPS) | mAP | 特点 | 自动驾驶应用 |
|------|----------|-----|------|------------|
| Faster R-CNN | 7 | 73.2% | 两阶段，精度高 | Waymo早期方案 |
| YOLO v2 | 40 | 76.8% | 单阶段，速度快 | Tesla AP2.0 |
| SSD | 46 | 74.3% | 多尺度特征 | MobileEye EyeQ4 |
| RetinaNet | 20 | 80.1% | Focal Loss | Apollo感知模块 |

**Tesla Autopilot 2.0架构（2016-2018）：**
```
8个摄像头输入
     ↓
┌──────────────────────────────────┐
│        HydraNet (早期版本)         │
├──────────────────────────────────┤
│  Backbone: ResNet-50变体          │
│  检测头: YOLO-like设计            │
│  任务:                           │
│  - 车辆检测 (2D Box)             │
│  - 车道线检测 (多项式拟合)        │
│  - 交通标志识别                  │
│  - 可行驶区域分割                │
└──────────────────────────────────┘
     ↓
  后处理 + 卡尔曼滤波跟踪
```

**2D检测的核心局限：**
1. **缺乏深度信息**：无法准确判断距离
2. **遮挡处理困难**：部分可见物体检测率低
3. **视角变换问题**：不同相机视角难以融合
4. **尺度歧义性**：远处大车vs近处小车

### 6.1.3 伪3D与深度估计 (2018-2019)

为了突破2D检测的局限，业界开始探索"伪3D"方案：

**主要技术路线：**

1. **单目深度估计 + 2D检测**
```
图像 -> CNN深度网络 -> 深度图
  ↓                      ↓
2D检测 ──────────> 3D框生成
```

2. **Pseudo-LiDAR (2018 CVPR)**
- 将深度图转换为伪点云
- 复用LiDAR检测算法
- 精度提升显著但计算量大

3. **多任务联合学习**
```
         共享特征提取器
              ↓
    ┌────┬────┬────┬────┐
    │2D框│深度│方向│尺寸│
    └────┴────┴────┴────┘
         ↓
    3D框参数回归
```

**代表性算法：**
- **MonoDIS (2019)**: 解耦2D和3D检测
- **M3D-RPN (2019)**: 2D/3D锚框联合设计
- **MonoPair (2020)**: 利用物体间关系约束

**中国方案实践：**
- 小鹏P7早期版本：双目深度估计+2D检测
- 蔚来ET7原型：多相机深度估计融合
- 地平线Matrix 1.0：专用深度估计加速

### 6.1.4 直接3D检测的兴起 (2019-2020)

2019年后，直接从图像回归3D框成为主流：

**SMOKE (2020 CVPR) - 单阶段3D检测基准：**
```
图像 -> DLA-34 backbone -> 关键点热图
                              ↓
                    3D中心投影 + 3D参数
                    (x,y,z,w,h,l,θ)
```

**CenterNet3D架构：**
```
┌─────────────────────────────────┐
│      特征提取 (ResNet/DLA)       │
└─────────────────────────────────┘
              ↓
┌─────────────────────────────────┐
│         热图预测头               │
│   - 中心点热图 (类别数×H×W)      │
│   - 局部偏移 (2×H×W)            │
│   - 深度预测 (1×H×W)            │
│   - 3D尺寸 (3×H×W)              │
│   - 方向角 (8×H×W)              │
└─────────────────────────────────┘
```

**FCOS3D (2021) - 无锚框3D检测：**
- 像素级3D框预测
- 2D中心度引导
- NMS-free设计

**工程优化技巧：**
1. **数据增强**：3D一致性约束下的增强
2. **深度归一化**：log-scale深度表示
3. **角度编码**：sin/cos分离回归
4. **不确定性建模**：预测置信度加权

### 6.1.5 工程化挑战与解决方案

**挑战1：多相机标定与同步**
```
解决方案架构：
┌──────────┐  时间戳对齐  ┌──────────┐
│ Camera 1 │ ─────────> │          │
├──────────┤            │  同步器   │
│ Camera 2 │ ─────────> │          │
├──────────┤            │ (硬件触发)│
│    ...   │ ─────────> │          │
└──────────┘            └──────────┘
                              ↓
                        统一时空坐标系
```

**挑战2：实时性要求**
- 输入分辨率权衡：1280×720 vs 640×360
- 模型压缩：INT8量化，通道剪枝
- 多线程流水线：检测-跟踪-融合并行

**挑战3：长尾场景**
- 数据采集：主动学习采样策略
- 仿真补充：特殊天气、罕见物体
- 在线学习：边缘案例增量更新

**量产部署指标要求：**
| 指标 | L2级别要求 | L4级别要求 |
|-----|-----------|-----------|
| 检测距离 | 150m | 200m |
| 检测精度 | >95% | >99% |
| 延迟 | <100ms | <50ms |
| 漏检率 | <1% | <0.01% |
| 误检率 | <5% | <0.1% |

## 6.2 BEV感知范式革命 (2020-2023)

### 6.2.1 为什么需要BEV

### 6.2.2 LSS: 开创性的视角转换

### 6.2.3 BEVDet系列: 工程化的典范

### 6.2.4 BEVFormer: Transformer的加入

### 6.2.5 时序BEV与4D感知

### 6.2.6 BEV感知的局限性

## 6.3 占据网络与世界模型 (2022-2024)

### 6.3.1 从检测框到占据网格

### 6.3.2 Occupancy Network架构演进

### 6.3.3 语义占据与通用障碍物

### 6.3.4 世界模型: 预测未来的感知

### 6.3.5 神经辐射场与可微渲染

### 6.3.6 生成式感知的未来

---