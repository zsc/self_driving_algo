# 第1章：前深度学习时代与早期探索 (Pre-2016)

> 在深度学习彻底改变自动驾驶之前，这个领域已经积累了数十年的技术沉淀。从DARPA挑战赛的荒漠试验场，到Google秘密车库里的改装普锐斯，再到德国高速公路上的Mercedes S-Class，每一步都在为即将到来的AI革命奠定基础。

## 1.1 DARPA挑战赛的遗产 (2004-2007)

### 1.1.1 Grand Challenge - 荒漠中的第一次尝试

2004年3月13日，莫哈韦沙漠，15支队伍的自动驾驶车辆在起跑线上整装待发。这是DARPA Grand Challenge的第一届比赛，142英里的沙漠赛道，没有一辆车完成。表现最好的卡内基梅隆大学的Sandstorm只跑了7.4英里就撞上了围栏。

```
2004 DARPA Grand Challenge 结果
┌────────────────────────────────────────────────┐
│ 排名 │ 团队          │ 车辆        │ 里程(英里) │
├────────────────────────────────────────────────┤
│ 1    │ CMU          │ Sandstorm   │ 7.40      │
│ 2    │ SciAutonics  │ SCIAUTONICS │ 6.70      │
│ 3    │ ENSCO        │ DAVID       │ 6.00      │
│ 4    │ Palos Verdes │ Palos Verde │ 5.20      │
│ 5    │ CMU          │ H1ghlander  │ 5.00      │
└────────────────────────────────────────────────┘
```

尽管结果惨淡，但这次比赛点燃了整个行业的热情。各团队迅速总结经验：
- **感知不足**：2D激光雷达无法准确识别地形
- **定位漂移**：纯GPS/INS在峡谷地带信号丢失
- **规划保守**：基于规则的路径规划过于僵化

### 1.1.2 技术栈的快速迭代 - 2005年的突破

仅仅18个月后，2005年10月，第二届Grand Challenge见证了历史性突破。Stanford的Stanley率先冲过终点，5辆车完成全程。

关键技术突破：
1. **3D激光雷达**：Velodyne HDL-64E成为标配
2. **概率机器人学**：Sebastian Thrun的概率SLAM
3. **机器学习初探**：用AdaBoost训练地形分类器

```
Stanley技术架构 (Stanford, 2005)
┌─────────────────────────────────────────┐
│            感知层 (Perception)           │
│  • 5x SICK激光雷达 (地面扫描)            │
│  • 1x Velodyne激光雷达 (360°环境)       │
│  • 单目相机 (道路检测)                   │
│  • 毫米波雷达 (障碍物)                   │
├─────────────────────────────────────────┤
│         定位与建图 (Localization)         │
│  • GPS/INS组合导航                       │
│  • 轮速计里程计                          │
│  • 概率地图匹配                          │
├─────────────────────────────────────────┤
│         规划决策 (Planning)              │
│  • A*全局路径规划                        │
│  • 动态窗口局部规划                      │
│  • 基于规则的行为决策                    │
└─────────────────────────────────────────┘
```

### 1.1.3 Urban Challenge - 从荒漠到城市

2007年的Urban Challenge将难度提升到新高度：60英里的城市环境，需要遵守交规、处理十字路口、完成超车和泊车。

获胜的CMU Boss系统展示了当时的技术天花板：

```
Boss系统规格 (CMU, 2007)
硬件配置：
- 11个激光雷达 (包括1个Velodyne HDL-64E)
- 5个毫米波雷达
- 2个高精度GPS/IMU
- 计算平台：10台Core2 Quad服务器
- 总功耗：3000W
- 传感器成本：>$500,000

软件架构：
┌──────────────────────────────────┐
│     Mission Planning             │
│   (任务规划：路网级决策)          │
└──────────────────────────────────┘
           ↓
┌──────────────────────────────────┐
│     Behavioral Executive         │
│   (行为执行：车道选择/换道决策)    │
└──────────────────────────────────┘
           ↓
┌──────────────────────────────────┐
│     Motion Planning              │
│   (运动规划：轨迹生成)            │
└──────────────────────────────────┘
```

### 1.1.4 DARPA挑战赛的技术遗产

DARPA挑战赛虽然结束了，但它培养的人才成为了自动驾驶行业的中坚力量：

| 参赛者 | DARPA时期角色 | 后续去向 |
|--------|--------------|----------|
| Sebastian Thrun | Stanford队长 | Google X创始人，Udacity创始人 |
| Chris Urmson | CMU技术负责人 | Google自动驾驶负责人，Aurora CEO |
| Bryan Salesky | CMU软件负责人 | Argo AI CEO |
| Dave Ferguson | CMU规划算法 | Google自动驾驶，Nuro创始人 |
| Anthony Levandowski | 510 Systems | Google自动驾驶，Uber ATG |
| Mike Montemerlo | Stanford SLAM专家 | Google自动驾驶核心成员 |

## 1.2 Google自动驾驶项目启动 (2009-2015)

### 1.2.1 Project Chauffeur的诞生

2009年，Google X实验室秘密启动Project Chauffeur。Sebastian Thrun说服Larry Page投入这个"登月计划"。初始团队几乎全部来自DARPA挑战赛的获胜队伍。

早期里程碑：
- **2009年**：7辆改装丰田普锐斯开始在山景城测试
- **2010年**：累计行驶14万英里未发生事故
- **2012年**：获得内华达州首张自动驾驶测试牌照
- **2014年**：发布Firefly原型车，没有方向盘和刹车

### 1.2.2 第一代技术架构

Google早期系统继承了Urban Challenge的架构，但在数据和计算上大幅升级：

```
Google自动驾驶系统架构 (2009-2012)
┌─────────────────────────────────────────────┐
│               传感器配置                      │
├─────────────────────────────────────────────┤
│ • Velodyne HDL-64E (车顶)                   │
│   - 64线激光雷达，10Hz，120万点/秒           │
│ • SICK LMS291 x4 (保险杠)                   │
│   - 单线激光雷达，75Hz，盲区覆盖             │
│ • Continental ARS 300 x3 (前后)             │
│   - 77GHz毫米波雷达，200m探测距离            │
│ • Point Grey相机 x2                         │
│   - 前向车道线/交通灯检测                    │
│ • Applanix POS LV 420                      │
│   - GPS/IMU组合，2cm定位精度                 │
└─────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────┐
│           核心算法模块                        │
├─────────────────────────────────────────────┤
│ 感知 (Perception)                           │
│ • 点云分割：Graph-based segmentation         │
│ • 物体跟踪：Multi-Hypothesis Tracking        │
│ • 分类识别：人工特征+SVM                      │
├─────────────────────────────────────────────┤
│ 定位 (Localization)                         │
│ • 高精地图：厘米级道路几何+语义               │
│ • 点云匹配：ICP+粒子滤波                     │
│ • 多传感器融合：EKF/UKF                      │
├─────────────────────────────────────────────┤
│ 预测 (Prediction)                           │
│ • 轨迹预测：高斯过程回归                      │
│ • 意图识别：隐马尔可夫模型                    │
├─────────────────────────────────────────────┤
│ 规划 (Planning)                             │
│ • 路径规划：A* + RRT*                       │
│ • 速度规划：S-T图搜索                        │
│ • 决策规则：有限状态机                        │
└─────────────────────────────────────────────┘
```

### 1.2.3 高精地图 - Google的秘密武器

与DARPA时代不同，Google意识到高精地图是破解感知难题的关键：

```
高精地图数据结构
Layer 1: 基础地图 (Base Map)
├── 道路几何：车道中心线、边界
├── 拓扑连接：车道连接关系
└── 静态标识：信号灯、标志牌位置

Layer 2: 语义地图 (Semantic Map)  
├── 车道属性：限速、转向限制
├── 交通规则：让行关系、停车线
└── 特殊区域：人行横道、施工区

Layer 3: 先验地图 (Prior Map)
├── 激光点云特征：用于定位匹配
├── 视觉特征：道路纹理、标志牌
└── 统计模型：车流模式、事故多发点
```

### 1.2.4 Firefly - 激进的无人驾驶原型

2014年，Google发布了完全自主设计的Firefly原型车。这个呆萌的小车代表了Google的技术自信：

- **激进设计**：无方向盘、无踏板、限速25mph
- **传感器冗余**：激光雷达+相机+毫米波+超声波
- **安全考虑**：泡沫前保险杠、软性挡风玻璃
- **用户体验**：只有"开始"和"停止"两个按钮

然而，Firefly最终被放弃，Google转向与传统车企合作。这个决定预示了L4级自动驾驶的漫长道路。

## 1.3 传统CV方法：HOG/SIFT/光流

在深度学习统治之前，计算机视觉依赖精心设计的特征工程。这些方法虽然"古老"，但其思想至今仍有价值。

### 1.3.1 HOG+SVM - 行人检测的经典组合

2005年，Dalal和Triggs提出的HOG(Histogram of Oriented Gradients)成为行人检测的标准方法：

```
HOG特征提取流程
输入图像(64x128)
    ↓
梯度计算 (Gradient)
    ├── Gx = I(x+1,y) - I(x-1,y)
    └── Gy = I(x,y+1) - I(x,y-1)
    ↓
方向直方图 (8x8 cells, 9 bins)
    ↓
块归一化 (2x2 cells/block, 50% overlap)
    ↓
特征向量 (3780维)
    ↓
SVM分类器
    ↓
检测结果
```

MobileEye的早期产品大量使用HOG变种：
- **检测率**：~90% @ 10^-4 FPPW
- **速度**：30fps on EyeQ2 (2008年)
- **局限**：对遮挡、姿态变化敏感

### 1.3.2 SIFT/SURF - 特征点匹配

SIFT(Scale-Invariant Feature Transform)在视觉SLAM中广泛应用：

```
SIFT在自动驾驶中的应用
1. 视觉里程计 (Visual Odometry)
   - 连续帧特征匹配
   - 相机位姿估计
   
2. 闭环检测 (Loop Closure)
   - 场景识别
   - 地图重定位
   
3. 交通标志识别
   - 模板匹配
   - 仿射不变性

性能指标 (circa 2010)：
- 特征提取：~200ms/frame (VGA)
- 匹配精度：>95% (良好光照)
- 鲁棒性：旋转360°，尺度2x，视角30°
```

### 1.3.3 光流法 - 运动估计

Lucas-Kanade光流是早期ADAS的核心算法：

```
光流在ADAS中的应用场景

1. 前车检测与跟踪
   光流场 → 运动分割 → 车辆检测
   
2. 车道偏离预警 (LDW)
   消失点估计 → 自车运动 → 偏离检测
   
3. 碰撞时间估计 (TTC)
   光流发散 → 膨胀率 → TTC = Z/Vz

算法性能 (Bosch ADAS, 2012)：
- 金字塔层数：3-4层
- 窗口大小：21x21像素  
- 处理速度：25fps @ QVGA
- 精度：~0.5像素 (亚像素插值)
```

### 1.3.4 立体视觉 - 深度估计

Subaru的EyeSight是立体视觉的成功案例：

```
EyeSight立体视觉系统 (2008-2015)

硬件配置：
┌──────────────────────────────┐
│  左相机        右相机         │
│    ←── 350mm基线 ──→         │
│  VGA CMOS    VGA CMOS        │
└──────────────────────────────┘

处理流程：
1. 立体校正 (Stereo Rectification)
2. 特征匹配 (Semi-Global Matching)
3. 视差计算 (Disparity)
   depth = f × baseline / disparity
4. 3D重建 (250万点/秒)

系统性能：
- 探测距离：1-110m
- 测距精度：±5% @ 40m
- 视场角：37° × 27°
- 处理延迟：<100ms
```

## 1.4 早期ADAS系统架构

### 1.4.1 MobileEye的崛起 - 从后装到前装

1999年成立的MobileEye，用一颗单目相机改变了ADAS行业格局。

```
MobileEye EyeQ系列演进
┌────────────────────────────────────────────────────┐
│ 代次   │ 年份  │ 算力    │ 功耗 │ 主要客户        │
├────────────────────────────────────────────────────┤
│ EyeQ1  │ 2004 │ 未公开  │ 2.5W │ 后装市场        │
│ EyeQ2  │ 2008 │ 2.5GIPS │ 2.5W │ BMW, GM, Volvo  │
│ EyeQ3  │ 2014 │ 256GIPS │ 3W   │ Tesla AP1, Audi │
│ EyeQ4  │ 2018 │ 2.5TOPS │ 3W   │ 38家OEM        │
└────────────────────────────────────────────────────┘

EyeQ3技术规格 (2014)：
- 双核MIPS + 4个VMP视觉处理器
- 处理5个摄像头输入
- 功能：AEB, ACC, LDW, TSR
- 成本：~$50 (量产价)
```

MobileEye的成功秘诀：
1. **算法硬件协同设计**：专用VMP加速HOG/SIFT运算
2. **极致功耗优化**：被动散热即可工作
3. **渐进式产品策略**：从单一功能到L2+

### 1.4.2 传统Tier1的ADAS方案

Bosch、Continental、Denso等传统供应商采用分布式架构：

```
典型Tier1 ADAS系统架构 (2010-2015)

传感器层：
┌─────────────────────────────────────────┐
│ 77GHz雷达  │ 前视相机 │ 角雷达×4 │ 超声波×12 │
└─────────────────────────────────────────┘
      ↓             ↓           ↓            ↓
   
ECU层 (分布式处理)：
┌──────────┐  ┌──────────┐  ┌──────────┐
│ ACC ECU  │  │ LKA ECU  │  │ AEB ECU  │
│ (Freescale│  │ (TI      │  │ (Infineon│
│  MPC5xxx)│  │  TDA2x)  │  │  Aurix)  │
└──────────┘  └──────────┘  └──────────┘
      ↓             ↓             ↓
      
车辆总线：
┌─────────────────────────────────────────┐
│            CAN/FlexRay总线               │
└─────────────────────────────────────────┘
      ↓
执行层：
┌──────────┐  ┌──────────┐  ┌──────────┐
│   ESP    │  │   EPS    │  │   TCU    │
│ (制动)   │  │ (转向)   │  │ (动力)   │
└──────────┘  └──────────┘  └──────────┘
```

### 1.4.3 ADAS功能分解与实现

主流ADAS功能的技术实现（2015年水平）：

| 功能 | 传感器需求 | 核心算法 | 计算需求 |
|------|-----------|---------|----------|
| **AEB (自动紧急制动)** | 77GHz雷达+相机 | TTC计算+目标分类 | ~100 MIPS |
| **ACC (自适应巡航)** | 77GHz雷达 | 目标跟踪+PID控制 | ~50 MIPS |
| **LKA (车道保持)** | 前视相机 | 车道线检测+横向控制 | ~200 MIPS |
| **BSD (盲点检测)** | 24GHz角雷达×2 | 目标检测+区域判断 | ~20 MIPS |
| **APA (自动泊车)** | 超声波×12+环视相机 | 空间检测+路径规划 | ~500 MIPS |

```
AEB系统决策逻辑示例

输入信号：
- 目标距离 d (雷达)
- 相对速度 vr (雷达多普勒)
- 目标类型 type (相机分类)
- 驾驶员状态 (转向/制动)

TTC计算：
if vr < 0:  # 接近目标
    ttc = -d / vr
else:
    ttc = ∞

制动策略：
if ttc < 0.6s:
    全力制动 (>1g)
elif ttc < 1.0s:
    部分制动 (0.6g) + 警告
elif ttc < 2.0s:
    预填充制动 + 警告
else:
    监控状态
```

### 1.4.4 成本与性能的平衡

早期ADAS面临的核心挑战是成本：

```
2015年典型L2配置成本分析

传感器成本：
- 77GHz前雷达:        $150
- 24GHz角雷达×4:      $200  
- 前视相机(VGA):      $50
- 超声波×12:          $60
传感器小计:           $460

计算平台：
- MobileEye EyeQ3:     $50
- ACC/AEB ECU:         $30
- 其他ECU:             $50
计算小计:             $130

软件许可：             $100
集成测试：             $200
─────────────────────────
总成本:               ~$900

对比：
- 整车成本占比: 2-3%
- 消费者付费意愿: $1500-2000
- OEM毛利要求: >40%
```

## 1.5 2014 Mercedes S-Class - 半自动驾驶的里程碑

### 1.5.1 Distronic Plus with Steering Assist

2013年发布的W222 S-Class是第一款真正意义上的L2级量产车：

```
S-Class自动驾驶功能矩阵

基础功能 (2014)：
┌────────────────────────────────────────┐
│ Distronic Plus (增强版ACC)             │
│ • 0-200km/h全速域                      │
│ • Stop&Go功能                          │
│ • 基于导航的速度调节                    │
├────────────────────────────────────────┤
│ Steering Assist (转向辅助)             │
│ • 0-60km/h车道保持                     │
│ • 60-200km/h车道居中                   │
│ • 弯道速度自适应                        │
├────────────────────────────────────────┤
│ Active Lane Change (主动变道)          │
│ • 驾驶员确认后执行                      │
│ • 雷达监控盲区                          │
│ • 自动回正                              │
└────────────────────────────────────────┘

高级功能 (2014-2016更新)：
- BAS Plus (交叉路口辅助)
- PRE-SAFE Plus (后碰撞保护)
- Night View Assist Plus (夜视行人检测)
- Traffic Sign Assist (交通标志识别)
```

### 1.5.2 传感器配置 - 豪华的冗余

S-Class采用了当时最豪华的传感器配置：

```
Mercedes S-Class传感器布局 (2014)

        前视立体相机
            ↓
    ┌───────────────┐
    │               │
远程雷达          远程雷达
    │   ┌─────┐    │
    │   │     │    │
近程雷达  [S]  近程雷达
    │   │     │    │
    │   └─────┘    │
近程雷达          近程雷达
    │               │
    └───────────────┘
          ↓
      后置雷达×2

详细规格：
1. 立体相机 (车内后视镜)
   - 6.5cm基线
   - 45°FOV
   - 50m有效距离
   
2. 长距雷达 (前保险杠)
   - 77GHz，200m探测距离
   - ±9°视角，0.1°分辨率
   
3. 短距雷达×6
   - 24GHz，80m探测距离
   - ±40°视角
   
4. 超声波×12
   - 4.5m探测距离
   - 用于泊车辅助
```

### 1.5.3 系统架构 - 分布式到域控制器的过渡

S-Class代表了从传统分布式向域控制器架构的过渡：

```
S-Class E/E架构

域控制器层：
┌─────────────────────────────────────┐
│      驾驶辅助域控制器                │
│   (Driver Assistance Domain)        │
│   • 双核处理器                       │
│   • 传感器融合                       │
│   • 轨迹规划                         │
└─────────────────────────────────────┘
            ↓
    FlexRay总线 (10Mbps)
            ↓
功能ECU层：
┌──────┐  ┌──────┐  ┌──────┐  ┌──────┐
│ ESP  │  │ EPS  │  │ TCU  │  │ BCM  │
└──────┘  └──────┘  └──────┘  └──────┘

软件架构特点：
1. 模型预测控制 (MPC) 用于轨迹跟踪
2. 多目标决策优化 (舒适性vs效率)
3. 驾驶员监控与接管逻辑
4. 功能降级策略
```

### 1.5.4 市场影响与技术启示

S-Class的成功带来了深远影响：

**技术验证**：
- 证明了L2级自动驾驶的技术可行性
- 建立了"驾驶员负责"的法律框架
- 确立了渐进式路线的主流地位

**产业影响**：
- 2015-2016年，各豪华品牌快速跟进
  - BMW 7系 (2015): Driving Assistant Plus
  - Audi A8 (2017): Traffic Jam Pilot (L3)
  - Volvo XC90 (2016): Pilot Assist

**经验教训**：
1. **传感器冗余必要性**：单一传感器无法覆盖所有场景
2. **人机交互的重要性**：接管提醒、状态显示
3. **ODD定义明确**：速度范围、道路类型、天气条件
4. **持续OTA的需求**：功能迭代、bug修复

```
L2功能使用率统计 (J.D. Power, 2016)
┌────────────────────────────────────┐
│ ACC使用率:        71%              │
│ LKA使用率:        52%              │
│ 自动泊车使用率:    23%              │
│ 盲点检测满意度:    89%              │
│ 整体安全感提升:    82%              │
└────────────────────────────────────┘
```

---

## 本章小结

前深度学习时代(Pre-2016)奠定了自动驾驶的技术基础：

1. **DARPA挑战赛**培养了第一代自动驾驶人才，验证了基础技术栈
2. **Google项目**证明了城市道路自动驾驶的可能性，确立了高精地图的重要性
3. **传统CV算法**虽然性能有限，但计算效率高，至今仍在嵌入式系统中使用
4. **早期ADAS**建立了产业化路径，培育了市场需求
5. **Mercedes S-Class**实现了L2级量产，开启了辅助驾驶的商业化时代

这个时期的核心特征：
- **技术路线**：规则主导，特征工程
- **传感器方案**：激光雷达for L4，雷达+相机for L2
- **商业模式**：L4追求一步到位，L2渐进式演进
- **关键挑战**：感知能力不足，极度依赖高精地图

2016年即将到来的深度学习革命，将彻底改变这一切。
