# 第4章：BEV与Transformer变革 (2021-2022)

## 4.1 引言：感知范式的根本性转变

2021-2022年是自动驾驶感知技术发生根本性变革的两年。如果说2016-2020年是深度学习在自动驾驶中站稳脚跟的阶段，那么这两年则见证了感知架构从2D到3D、从透视图到鸟瞰图（BEV）、从CNN到Transformer的全面升级。

### 为什么是2021年？

多个技术趋势在2021年形成共振：

1. **算力突破临界点**：车规级芯片算力突破100 TOPS，使得复杂的BEV转换和Transformer计算成为可能
2. **Transformer在CV领域成熟**：ViT、DETR等工作证明了Transformer在视觉任务上的有效性
3. **数据规模效应显现**：Tesla积累的数十亿英里行驶数据开始展现威力
4. **高精地图的局限性暴露**：维护成本高、更新慢、覆盖范围有限

### BEV：统一的表征空间

BEV（Bird's Eye View）并非新概念，但将其作为自动驾驶的核心表征却是革命性的：

```
传统方案：多相机独立感知
┌─────┐  ┌─────┐  ┌─────┐
│前视  │  │左视  │  │右视  │
└──┬──┘  └──┬──┘  └──┬──┘
   ↓        ↓        ↓
独立2D检测  独立2D检测  独立2D检测
   ↓        ↓        ↓
   └────────┴────────┘
         后融合
           ↓
       3D世界理解

BEV方案：统一空间感知
┌─────┐  ┌─────┐  ┌─────┐
│前视  │  │环视  │  │后视  │
└──┬──┘  └──┬──┘  └──┬──┘
   └────────┼────────┘
           ↓
      特征级融合
           ↓
      BEV特征图
           ↓
    统一3D感知输出
```

## 4.2 2021年上半年：BEV感知的学术探索

### DETR3D：开创性的端到端3D检测

2021年3月，DETR3D论文发表，首次将Transformer的object query机制引入3D目标检测：

**核心创新**：
- 使用可学习的3D reference points作为query
- 通过2D-3D几何投影采样多视角特征
- 无需复杂的后处理（NMS等）

**架构示意**：
```
Multi-view Images
      ↓
   ResNet50
      ↓
  2D Features
      ↓
┌──────────────┐
│  3D-to-2D    │
│  Projection  │
└──────────────┘
      ↓
Feature Sampling
      ↓
  Transformer
    Decoder
      ↓
  3D Bboxes
```

### BEVDet：纯视觉BEV感知的里程碑

2021年6月，BEVDet提出了LSS（Lift-Splat-Shoot）的改进版本：

**关键技术**：
1. **显式深度估计**：为每个像素预测深度分布
2. **View Transformation**：将2D特征"提升"到3D空间
3. **BEV Encoder**：在BEV空间进行特征编码

**性能突破**：
- nuScenes数据集mAP: 29.8% → 39.2%
- 推理速度：30 FPS on V100
- 纯视觉方案接近LiDAR性能

## 4.3 Tesla AI Day (2021.8.19)：BEV+Transformer的工业化宣言

### HydraNet：多头网络的极致设计

Tesla展示的HydraNet震撼了整个行业：

```
                HydraNet架构
    ┌─────────────────────────────────┐
    │        8个相机 @ 36Hz            │
    └────────────┬────────────────────┘
                 ↓
    ┌─────────────────────────────────┐
    │     RegNet Backbone              │
    │   (高效的CNN特征提取器)           │
    └────────────┬────────────────────┘
                 ↓
    ┌─────────────────────────────────┐
    │     BiFPN多尺度融合               │
    └────────────┬────────────────────┘
                 ↓
         ┌───────┴───────┐
         ↓               ↓
    ┌─────────┐    ┌─────────┐
    │Transformer│    │CNN Heads│
    │  Heads   │    │         │
    └─────────┘    └─────────┘
         ↓               ↓
    Detection      Segmentation
    Tracking       Depth
    Lane           Attributes
```

**48个不同的输出头**：
- 目标检测（车、人、交通设施等）
- 语义分割（可行驶区域、车道线）
- 深度估计
- 运动预测
- 交通灯状态
- 道路结构理解

### Vector Space：从像素到向量

Tesla的Vector Space代表了认知层次的提升：

**传统表征 vs Vector Space**：
```
像素级表征：              向量化表征：
████████████             Lane: {
██░░░░██░░░██              type: "divider",
██░░░░██░░░██              points: [(x1,y1), ...],
████████████               confidence: 0.95
                         }
需要后处理提取语义        直接输出结构化信息
```

### Spatial RNN：时序记忆的引入

**Video Module架构**：
- 将BEV特征在时间维度上排队
- 使用Spatial RNN维护场景记忆
- Feature queue长度：27帧（~1秒历史）

```
时间步: t-26  t-25  ...  t-1   t
        ↓     ↓         ↓    ↓
      [BEV] [BEV] ... [BEV] [BEV]
        ↓     ↓         ↓    ↓
      ┌─────────────────────────┐
      │    Spatial RNN           │
      │  (ConvGRU/ConvLSTM)      │
      └─────────────────────────┘
                ↓
        时序融合的BEV特征
```

## 4.4 中国市场的激进探索与安全警示

### 2021年8月12日：蔚来ES8 NOP事故

**事故概要**：
- 地点：福建莆田高速
- 情况：车主启用NOP（Navigate on Pilot）功能
- 结果：撞击高速公路施工区域，车主不幸身亡

**技术分析**：
1. **静态障碍物检测失效**：施工锥桶识别不足
2. **地图信息滞后**：高精地图未更新施工信息
3. **预警系统设计缺陷**：未能有效提醒驾驶员接管

**行业影响**：
- 工信部要求车企规范宣传，不得夸大功能
- "自动驾驶"改为"辅助驾驶"成为行业共识
- OTA功能审查趋严

### 各家应对策略

**小鹏汽车**：
- 推出"安全驾驶提醒"功能
- 驾驶员监控系统（DMS）强制开启
- NGP使用需要考试认证

**理想汽车**：
- NOA功能默认关闭
- 多重确认机制
- 强调"人类驾驶员负最终责任"

**特斯拉**：
- FSD Beta仍未进入中国
- Autopilot功能相对保守
- 加强本土化数据收集

## 4.5 BEV感知的技术爆发期

2021年下半年到2022年上半年，学术界和工业界围绕BEV感知展开了激烈的技术竞赛。

### BEVFormer (2022.3)：Query-based的优雅方案

BEVFormer提出了一种基于Transformer的端到端BEV感知框架：

**核心创新**：
1. **BEV Queries**：预定义的BEV网格查询
2. **Spatial Cross-Attention**：空间注意力机制
3. **Temporal Self-Attention**：时序自注意力

```
BEVFormer架构
┌────────────────────────────────┐
│   Multi-camera Images @ t       │
└────────────┬───────────────────┘
             ↓
     ┌──────────────┐
     │   Backbone   │
     │  (ResNet101) │
     └──────┬───────┘
             ↓
    ┌────────────────┐
    │  BEV Queries   │←─── Learnable Parameters
    │  (H×W×C)       │
    └────────┬───────┘
             ↓
    ┌─────────────────────────┐
    │  Spatial Cross-Attention │
    │  (Deformable Attention)  │
    └────────┬─────────────────┘
             ↓
    ┌─────────────────────────┐
    │ Temporal Self-Attention  │←── History BEV @ t-1
    └────────┬─────────────────┘
             ↓
         BEV Features
             ↓
    ┌────────┴────────┐
    ↓                 ↓
3D Detection    Map Segmentation
```

**性能指标**：
- nuScenes test: 41.6 mAP, 56.9 NDS
- 计算效率：相比DETR3D减少50%计算量
- 时序融合带来3.5 mAP提升

### BEVDepth (2022.6)：深度监督的重要性

BEVDepth的核心洞察：准确的深度估计是BEV转换的关键。

**技术要点**：
1. **显式深度监督**：使用LiDAR点云生成深度真值
2. **Camera-aware深度预测**：考虑相机内参
3. **高效的View Transformer**：优化CUDA实现

```
深度估计网络设计
Image Features ──┬──→ Depth Net ──→ Depth Distribution
                 │                         ↓
Camera Intrinsics┘                   Depth Bins
                                          ↓
                                    View Transform
                                          ↓
                                     BEV Features
```

**关键改进**：
- 深度估计精度：相对误差从15%降至9%
- 3D检测性能：47.5 mAP (+8.3 vs baseline)
- 推理速度：41.4 FPS on 3090

### PersFormer (2021.10)：透视变换的新思路

PersFormer提出了基于透视变换的3D位置编码：

**创新点**：
1. **3D坐标生成**：直接在3D空间采样
2. **透视感知采样**：考虑透视畸变
3. **无需深度估计**：端到端学习投影

### 各方案对比分析

| 方法 | 深度估计 | 时序融合 | mAP | NDS | FPS |
|------|---------|---------|-----|-----|-----|
| BEVDet | 隐式 | × | 39.2 | 47.9 | 30 |
| BEVFormer | 隐式 | ✓ | 41.6 | 56.9 | 10 |
| BEVDepth | 显式监督 | × | 47.5 | 53.5 | 41 |
| PersFormer | 无需 | × | 40.7 | 50.9 | 25 |

## 4.6 2022年：FSD Beta的大规模验证

### 版本迭代轨迹

2022年是FSD Beta快速迭代的一年：

**V10.x系列（2022.1-6）**：
- 10.0：首次大规模推送（1000→10000用户）
- 10.2：改进左转判断
- 10.8：城市街道导航能力
- 10.12：蠕行行为优化

**V11.x系列（2022.11）**：
- 统一高速和城市栈
- 单一神经网络处理所有场景
- 取消高速/城市模式切换

### 真实世界反馈

**正面反馈**：
- 复杂路口处理能力显著提升
- 无保护左转成功率达到85%
- 施工区域识别准确性提高

**持续挑战**：
- 行人意图预测仍有不足
- 雨雪天气性能下降明显
- 地图缺失区域表现不稳定

### 数据飞轮效应

```
FSD Beta数据循环
┌─────────────┐
│  用户使用    │
│  (10万+车辆) │
└──────┬──────┘
       ↓
┌─────────────┐
│  触发条件    │
│  Shadow Mode │
└──────┬──────┘
       ↓
┌─────────────┐
│  数据上传    │
│  (Corner Cases)│
└──────┬──────┘
       ↓
┌─────────────┐
│  自动标注    │
│  +人工审核   │
└──────┬──────┘
       ↓
┌─────────────┐
│  模型训练    │
│  Dojo超算    │
└──────┬──────┘
       ↓
┌─────────────┐
│  OTA更新     │
│  (2-4周周期) │
└──────┴──────┘
```

## 4.7 Occupancy Network：从检测到理解

### 为什么需要Occupancy？

传统3D检测的局限：
1. **语义类别有限**：只能检测预定义类别
2. **形状假设过强**：用3D框表示所有物体
3. **遮挡处理困难**：部分可见物体难以准确检测

Occupancy Network的优势：
```
传统3D检测：              Occupancy表征：
┌──┐ ┌──┐ ┌──┐          ████████████████
│车│ │人│ │？│          ██░░██░░████░░██
└──┘ └──┘ └──┘          ██░░░░░░░░░░░░██
                         ████████████████
离散框表示                连续体素表示
类别受限                  通用障碍物理解
```

### Tesla的实现（2022 AI Day）

**网络结构**：
1. **体素化表征**：200m×200m×20m空间
2. **分辨率**：0.5m×0.5m×0.5m体素
3. **输出通道**：占用概率+语义类别

**技术细节**：
```
BEV Features
     ↓
3D Deconvolution
     ↓
┌─────────────┐
│  Z-Lifting   │ (将BEV提升到3D)
└──────┬──────┘
       ↓
┌─────────────┐
│ 3D ConvNet   │
│  (稀疏卷积)  │
└──────┬──────┘
       ↓
Occupancy Volume
  - Free Space
  - Occupied
  - Unknown
```

### 国内跟进：OpenOccupancy基准

2022年底，国内团队发布OpenOccupancy：

**数据集规模**：
- 基于nuScenes扩展
- 200万个3D体素标注
- 16个语义类别

**基准方法**：
- TPVFormer：三视图表征
- SurroundOcc：环视占用预测
- OccFormer：Transformer-based方案

## 4.8 向量化地图与在线建图

### 高精地图的困境

到2022年，高精地图方案的问题日益凸显：

**成本问题**：
- 制作成本：$1000-2000/公里
- 维护成本：每年10-20%的制作成本
- 中国高速公路：14万公里
- 城市道路：>400万公里

**更新延迟**：
- 道路施工：数周到数月延迟
- 临时变更：无法及时反映
- 新建道路：半年以上延迟

### Neural Map Prior：神经网络地图先验

2022年，多个团队提出用神经网络实时构建地图：

```
传统方案：                在线建图方案：
┌──────────┐            ┌──────────┐
│ HD Map   │            │ Sensors  │
│ Database │            └────┬─────┘
└────┬─────┘                 ↓
     ↓                  ┌──────────┐
┌──────────┐            │Neural Net│
│Map Match │            └────┬─────┘
└────┬─────┘                 ↓
     ↓                  ┌──────────┐
Map Elements            │Vector Map│
                        │(实时生成) │
                        └──────────┘
```

### HDMapNet (2021.7)：开创性工作

**核心思想**：
- 将地图构建作为语义分割任务
- 直接从图像预测向量化地图元素
- 无需高精地图先验

**网络设计**：
```
Multi-view Images
        ↓
   CNN Backbone
        ↓
   View Transform
        ↓
    BEV Features
        ↓
   ┌────┴────┐
   ↓         ↓
Semantic  Instance
  Seg       Seg
   ↓         ↓
   └────┬────┘
        ↓
  Vectorization
        ↓
  Lane Topology
```

### VectorMapNet (2022.6)：端到端向量化

**改进点**：
1. **直接输出向量**：跳过栅格化步骤
2. **自回归解码**：逐点生成折线
3. **拓扑关系建模**：车道连接关系

**性能对比**：
| 方法 | mAP | 推理时间 | 需要HD Map |
|------|-----|---------|------------|
| 传统匹配 | 85.2 | 5ms | ✓ |
| HDMapNet | 49.3 | 35ms | × |
| VectorMapNet | 61.8 | 25ms | × |

### MapTR (2022.8)：Transformer建图

MapTR将地图元素建模为一组可学习的queries：

**架构特点**：
- 统一的置换等变建模
- 层级query设计
- 端到端可微分

```
MapTR Query设计
┌─────────────────┐
│ Point Queries   │ (关键点)
└────────┬────────┘
         ↓
┌─────────────────┐
│ Line Queries    │ (车道线)
└────────┬────────┘
         ↓
┌─────────────────┐
│ Polygon Queries │ (区域)
└─────────────────┘
```

## 4.9 2022年末：行业格局重塑

### 小鹏P7高速事故（2022.8.10）

**事故经过**：
- 地点：宁波某高速
- 场景：前方故障车辆停在车道内
- 结果：NGP未能识别静止车辆，追尾事故

**技术反思**：
1. **AEB失效场景**：高速静止目标
2. **视觉感知盲区**：强光/阴影干扰
3. **毫米波雷达限制**：过滤静止物体

### 行业技术路线收敛

到2022年底，主要玩家的技术选择趋于一致：

**共识形成**：
```
2021年初分歧：           2022年底共识：
┌──────────┐           ┌──────────┐
│多路径探索 │           │ BEV统一   │
├──────────┤    →      ├──────────┤
│·2D/3D混合│           │·BEV为核心 │
│·规则主导 │           │·学习为主 │
│·模块分离 │           │·端到端趋势│
└──────────┘           └──────────┘
```

### 中国玩家的BEV实践

**小鹏汽车XNGP**：
- XNet：自研BEV感知网络
- 动态物体：30类识别
- 静态环境：20cm精度建图

**理想汽车AD Max**：
- 双Orin X芯片
- BEV+Occupancy
- 算法算力协同设计

**华为ADS 2.0**：
- GOD网络（通用障碍物检测）
- RCR网络（道路拓扑推理）
- 无高精地图依赖

**毫末智行**：
- Transformer大模型路线
- 时空联合建模
- CLIP视觉-语言预训练

### BEV成为事实标准

**行业影响**：
1. **人才流动**：BEV/3D视觉人才需求暴增
2. **开源生态**：OpenMMLab等开源BEV工具链
3. **硬件适配**：芯片厂商优化BEV算子
4. **数据标注**：3D标注成为新瓶颈

## 4.10 本章总结：范式转换的深远影响

### 技术层面的革命

2021-2022年见证了自动驾驶感知的根本性变革：

**从2D到3D的跨越**：
- 2D检测的天花板被打破
- 3D空间理解成为标配
- 深度估计成为核心能力

**从透视到BEV的统一**：
- 多相机融合问题得到解决
- 时序信息自然整合
- 规划控制接口简化

**从CNN到Transformer的进化**：
- 长程依赖建模能力
- 统一的架构范式
- 更好的扩展性

### 产业格局的重塑

**技术门槛提升**：
```
2020年前：              2022年后：
入门门槛                专业门槛
├─2D检测即可            ├─BEV感知必备
├─开源模型够用          ├─自研架构要求
├─小团队可行            ├─大团队协作
└─10人团队              └─100+人团队
```

**竞争焦点转变**：
- 从"能不能做"到"做得多好"
- 从"功能完整"到"体验优化"
- 从"演示Demo"到"量产交付"

### 中国市场的独特路径

**快速跟进与创新**：
1. **学术突破**：BEVFormer等工作获得国际认可
2. **工程落地**：小鹏/理想/华为快速产品化
3. **成本优化**：大疆等公司的极致成本控制

**事故推动的理性回归**：
- 蔚来、小鹏事故引发监管关注
- "自动驾驶"宣传降温
- 用户教育和预期管理加强

### 关键经验教训

**技术层面**：
1. **统一表征的重要性**：BEV提供了感知到规划的统一接口
2. **数据驱动的威力**：大规模数据+神经网络超越传统方法
3. **架构创新的价值**：Transformer带来质的飞跃

**工程层面**：
1. **渐进式部署**：FSD Beta的迭代验证模式
2. **安全冗余设计**：多传感器融合仍有价值
3. **用户预期管理**：技术能力与宣传的平衡

### 对未来的启示

2021-2022年的BEV革命奠定了后续发展基础：

**端到端的必然性**：
- BEV统一表征为端到端铺平道路
- 模块边界逐渐模糊
- 数据驱动成为主流

**规模化的挑战**：
```
技术验证 → 工程化 → 规模化
  完成      进行中    待突破
```

**新的技术前沿**：
- 世界模型：从感知到理解
- 生成式方法：从判别到生成
- 大模型驱动：从专用到通用

### 历史定位

2021-2022年是自动驾驶发展史上的关键节点：

1. **技术范式确立**：BEV+Transformer成为主流
2. **产业格局初定**：头部玩家拉开差距
3. **商业模式探索**：L2+渐进路线获得认可

这两年不仅见证了技术的飞跃，更重要的是确立了自动驾驶的"第一性原理"：**通过神经网络直接从传感器数据学习驾驶**。这一理念的确立，为2023年的端到端革命埋下了伏笔。

正如Tesla AI负责人Andrej Karpathy所说："Software 2.0时代，我们不再编写程序，而是收集数据、定义损失函数，让神经网络自己学习程序。"BEV革命正是这一理念在自动驾驶领域的完美体现。

---

*第4章完*