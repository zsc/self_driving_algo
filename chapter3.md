# 第3章：感知架构大爆发 (2019-2020)

## 章节概述

2019-2020年是自动驾驶感知技术的转折点。这两年间，行业从简单的2D检测快速演进到复杂的3D感知，多任务学习网络开始大规模应用，BEV（鸟瞰图）感知范式初露端倪。特斯拉在2019年Autonomy Day上展示的FSD芯片和神经网络架构震撼业界，而2020年COVID疫情意外推动了无人配送的落地。同时，中国自动驾驶产业在这一时期快速崛起，NOA（Navigate on Autopilot）功能开始在多家车企落地。

## 3.1 2019 Tesla Autonomy Day：FSD芯片与算法协同设计的里程碑

### 3.1.1 FSD芯片架构革新

2019年4月22日，特斯拉举办了震撼业界的Autonomy Day。最引人注目的是其自研的FSD（Full Self-Driving）芯片，这标志着特斯拉彻底摆脱了对Mobileye和NVIDIA的依赖。

```
FSD芯片关键参数：
┌─────────────────────────────────────────┐
│         Tesla FSD Computer (HW3.0)      │
├─────────────────────────────────────────┤
│ 制程工艺：     14nm FinFET (三星代工)    │
│ 算力：         144 TOPS (INT8)          │
│ NPU数量：      2个独立NPU               │
│ 单NPU算力：    72 TOPS                  │
│ CPU：          12核ARM Cortex-A72       │
│ GPU：          1 GHz Mali G71 MP12      │
│ 内存：         8GB LPDDR4               │
│ 功耗：         72W (整板)               │
│ 成本：         ~$190 (量产成本)         │
└─────────────────────────────────────────┘
```

### 3.1.2 神经网络架构创新

特斯拉展示的神经网络架构相比之前有了质的飞跃：

**HydraNet多头网络架构**
```
                 共享骨干网络 (RegNet)
                        ↓
    ┌──────────┬──────────┬──────────┬──────────┐
    │          │          │          │          │
  检测头     车道线头    可行驶区域   交通标志   深度估计
   Head      Head        Head       Head       Head
    │          │          │          │          │
  输出1      输出2       输出3      输出4      输出5
```

关键创新点：
- **共享特征提取器**：使用RegNet作为骨干网络，参数量50M，相比ResNet-50减少了计算量但提升了准确率
- **多任务学习**：单个网络同时处理检测、分割、深度估计等多个任务
- **时序融合**：引入时间维度，利用视频连续帧提升检测稳定性

### 3.1.3 数据引擎与Shadow Mode

特斯拉首次详细介绍了其"影子模式"（Shadow Mode）数据收集系统：

1. **被动数据收集**：车辆在后台运行神经网络，但不控制车辆
2. **分歧检测**：当神经网络预测与人类驾驶行为不一致时，触发数据上传
3. **自动标注**：利用车队数据自动生成训练标签

数据规模（2019年）：
- 车队规模：超过50万辆配备FSD硬件的车辆
- 日均里程：2000万英里
- 月度数据量：1PB级别的视频数据

## 3.2 多任务学习网络兴起：从单一功能到统一架构

### 3.2.1 传统方案的局限性

2019年之前的自动驾驶感知系统通常采用独立模块设计：

```
传统模块化设计：
┌──────────┐  ┌──────────┐  ┌──────────┐
│ 车辆检测  │  │ 车道检测  │  │ 标志识别  │
│  模型1   │  │  模型2   │  │  模型3   │
└──────────┘  └──────────┘  └──────────┘
     ↓             ↓             ↓
  YOLO v3      LaneNet      Sign-CNN
  (30 FPS)     (20 FPS)     (15 FPS)

问题：
• 计算冗余：每个模型独立提取特征
• 内存占用大：多个模型同时加载
• 难以协同：模块间信息无法共享
```

### 3.2.2 多任务学习架构演进

**第一代：硬参数共享（Hard Parameter Sharing）**

最早期的多任务网络采用简单的硬参数共享：

```
输入图像
    ↓
共享编码器 (ResNet-50)
    ↓
┌────┴────┬────┴────┐
检测分支  分割分支  深度分支
```

代表工作：
- **MultiNet (2016)**：最早的端到端多任务驾驶网络
- **DLT-Net (2018)**：可行驶区域+车道线联合检测
- **YOLOP (2019)**：检测+可行驶区域+车道线三任务

**第二代：注意力机制增强**

2019年开始，注意力机制被引入多任务学习：

```
TaskPrompter架构 (2019)：
         输入特征
            ↓
    ┌───────────────┐
    │  任务注意力模块 │
    └───────────────┘
      ↙    ↓    ↘
  任务1  任务2  任务3
  权重   权重   权重
```

关键技术：
- **任务相关性建模**：学习不同任务间的依赖关系
- **动态权重调整**：根据场景自适应调整任务权重
- **梯度平衡**：解决多任务训练中的梯度冲突问题

### 3.2.3 产业应用案例

**Mobileye EyeQ5架构**

虽然特斯拉抛弃了Mobileye，但后者在2019年发布的EyeQ5展示了另一种多任务设计思路：

```
EyeQ5多任务处理单元：
┌─────────────────────────────────┐
│       EyeQ5 (24 TOPS)           │
├─────────────────────────────────┤
│ • 4个多线程CPU集群              │
│ • 18个视觉处理器(CVP)           │
│ • 深度学习加速器(DLA)           │
│ • 2个可编程宏阵列(PMA)          │
└─────────────────────────────────┘
         ↓
  并行处理15+个视觉任务
```

**地平线Matrix 2.0**

中国本土芯片厂商地平线在2019年推出的Matrix 2.0展示了高效的多任务处理：

- 4路摄像头输入
- 同时运行8个神经网络
- 单芯片实现360°感知

## 3.3 伪激光雷达与深度估计：纯视觉3D感知的突破

### 3.3.1 伪激光雷达（Pseudo-LiDAR）概念

2019年康奈尔大学提出的Pseudo-LiDAR论文引发了业界对纯视觉3D感知的重新思考：

**核心思想**：
1. 从立体视觉或单目深度估计获得深度图
2. 将深度图转换为3D点云（伪激光雷达）
3. 使用成熟的点云检测算法进行3D目标检测

```
Pseudo-LiDAR处理流程：
┌──────────┐     ┌──────────┐     ┌──────────┐
│  左图像   │ --> │  深度估计 │ --> │ 3D点云   │
│  右图像   │     │  网络    │     │  生成    │
└──────────┘     └──────────┘     └──────────┘
                                         ↓
                                  ┌──────────┐
                                  │ PointNet │
                                  │ 3D检测   │
                                  └──────────┘
```

### 3.3.2 单目深度估计技术爆发

2019-2020年，单目深度估计取得重大突破：

**关键方法对比**：

| 方法 | 年份 | 特点 | KITTI深度误差 |
|------|------|------|--------------|
| Monodepth2 | 2019 | 自监督学习 | 0.115 |
| PackNet-SfM | 2019 | 3D卷积打包 | 0.107 |
| Depth Hints | 2019 | 立体监督 | 0.098 |
| FeatDepth | 2020 | 特征度量学习 | 0.088 |

**特斯拉的深度估计网络**

特斯拉在2019年展示的深度网络采用了独特的设计：

```
深度网络架构：
输入: 1280×960 RGB图像
        ↓
特征提取: RegNet骨干
        ↓
多尺度特征金字塔
   ↙    ↓    ↘
粗糙  中等  精细
深度  深度  深度
   ↘    ↓    ↙
    深度融合
        ↓
输出: 256×144 深度图
```

创新点：
- **自监督预训练**：利用时序一致性
- **语义引导**：物体类别信息辅助深度估计
- **边缘保持**：保持物体边界的深度不连续性

### 3.3.3 产业化挑战与解决方案

**挑战1：计算复杂度**
- 问题：深度估计网络计算量大
- 解决：模型量化、剪枝、知识蒸馏

**挑战2：尺度模糊性**
- 问题：单目深度缺乏绝对尺度
- 解决：利用已知物体尺寸、地面约束

**挑战3：远距离精度**
- 问题：远处物体深度误差大
- 解决：分段深度估计、注意力机制

## 3.4 2020年1月：德国批准Tesla Autopilot合法化的技术影响

### 3.4.1 监管认证要求

德国KBA（联邦机动车管理局）的认证要求推动了技术标准化：

```
认证技术要求：
┌──────────────────────────────────┐
│     功能安全 (ISO 26262)         │
├──────────────────────────────────┤
│ • ASIL-D等级系统设计             │
│ • 冗余传感器配置                 │
│ • 失效安全机制                   │
│ • 实时监控与降级策略             │
└──────────────────────────────────┘
```

### 3.4.2 技术适应性改进

为满足欧洲法规，特斯拉进行了多项技术改进：

1. **增强的驾驶员监控**
   - 方向盘扭矩检测频率提升
   - 注意力监测算法优化

2. **场景适应性**
   - 欧洲道路标志识别
   - 环岛处理逻辑
   - 窄路会车策略

3. **功能限制**
   - 自动变道需确认
   - 速度限制遵守
   - 施工区域检测增强

### 3.4.3 对全球市场的示范效应

德国的批准产生了连锁反应：
- 欧盟其他国家跟进
- 中国加速NOA功能审批
- 技术标准趋同化

## 3.5 2020 COVID推动无人配送发展：感知技术的新挑战

### 3.5.1 无人配送场景的独特需求

疫情期间，无人配送从概念快速走向应用，带来新的技术挑战：

```
配送场景 vs 乘用车场景：
┌───────────────┬──────────────────┐
│   无人配送     │     乘用车       │
├───────────────┼──────────────────┤
│ 速度: <30km/h │ 速度: 0-120km/h  │
│ 环境: 园区    │ 环境: 开放道路    │
│ 路线: 固定    │ 路线: 任意        │
│ 交互: 行人密集 │ 交互: 车辆为主    │
└───────────────┴──────────────────┘
```

### 3.5.2 低速场景的感知优化

**美团无人配送车感知方案**（2020年2月投入武汉）：

```
传感器配置：
     前视激光雷达(16线)
           ↓
    ┌──────────────┐
    │              │
环视 │   配送车     │ 环视
相机 │              │ 相机
    │              │
    └──────────────┘
           ↑
     超声波雷达阵列

特点：
• 成本控制在2万元以内
• 360°无死角感知
• 重点优化行人检测
```

**京东无人配送感知策略**：
1. 高精地图+视觉定位
2. 行人意图预测
3. 可通行空间实时更新

### 3.5.3 疫情期间的快速迭代

**数据积累加速**：
- 2020年2-6月，中国无人配送车累计运行超过100万公里
- 收集了大量"最后一公里"场景数据

**算法快速迭代**：
- 口罩佩戴下的行人检测
- 临时路障识别
- 消毒作业车辆避让

## 3.6 BEV感知初现端倪：从图像空间到鸟瞰图空间

### 3.6.1 BEV感知的动机

传统前视图感知的局限性逐渐显现：

```
前视图 vs BEV空间：

前视图问题：            BEV优势：
┌──────────┐         ┌──────────┐
│ 透视畸变  │         │ 度量准确  │
│ 遮挡严重  │   -->   │ 全局视角  │  
│ 多相机融合难│         │ 便于规划  │
└──────────┘         └──────────┘
```

### 3.6.2 早期BEV方法

**IPM（逆透视映射）时代**（2019年之前）：
- 假设地面平坦
- 简单的几何变换
- 仅适用于车道线、可行驶区域

**LSS（Lift, Splat, Shoot）突破**（2020年）：

```
LSS处理流程：
1. Lift: 图像特征 + 深度分布 → 3D特征
2. Splat: 3D特征 → BEV网格
3. Shoot: BEV特征 → 下游任务

     图像特征           
         ↓
    深度分布预测
         ↓
    3D特征云
         ↓
    体素化(Voxelize)
         ↓
    BEV特征图
```

关键创新：
- 显式的深度概率分布建模
- 可微的3D-2D投影
- 端到端训练

### 3.6.3 产业先驱探索

**特斯拉的Vector Space**（2019年开始内部研发）：

虽然特斯拉在2021年AI Day才公开BEV架构，但从2019年的专利和招聘信息可以看出其已在探索：

1. "Vector Space"概念：将感知结果投影到统一的3D空间
2. 多摄像头时空融合
3. 隐式的BEV表征学习

**百度Apollo的BEV尝试**：

```
Apollo 5.5 (2020年) BEV模块：
┌─────────────────────────┐
│   6个环视摄像头输入      │
└─────────────────────────┘
            ↓
    ┌───────────────┐
    │  特征提取网络  │
    └───────────────┘
            ↓
    ┌───────────────┐
    │  BEV转换模块   │
    └───────────────┘
            ↓
    ┌───────────────┐
    │  HD Map融合    │
    └───────────────┘
```

## 3.7 中国NOA功能开始落地：本土化创新与挑战

### 3.7.1 中国NOA先行者

2020年，中国多家车企开始推出NOA（Navigate on Autopilot）类功能：

**小鹏NGP（Navigation Guided Pilot）**（2020年10月）：
- 首个量产的高速自主导航辅助
- 覆盖自动超车、自动变道、自动上下匝道
- 基于高精地图的强依赖方案

**蔚来NOP（Navigate on Pilot）**（2020年10月）：
- Mobileye EyeQ4芯片方案
- 保守的安全策略
- 用户激活率超过50%

**理想NOA**（2020年12月）：
- 地平线征程3芯片
- 视觉为主的感知方案
- 成本控制在3000元以内

### 3.7.2 本土化技术创新

**中国特色场景处理**：

```
中国道路挑战：
┌────────────────────────────┐
│ 1. 加塞频繁                │
│ 2. 车道线不清晰            │
│ 3. 施工区域多              │
│ 4. 非标准道路设计          │
│ 5. 混合交通流              │
└────────────────────────────┘
```

技术应对：
1. **激进的变道策略**：相比特斯拉更激进的变道时机判断
2. **高精地图依赖**：弥补车道线检测的不足
3. **本地化训练数据**：大量中国道路场景数据

### 3.7.3 技术架构对比

| 厂商 | 芯片方案 | 感知方案 | 地图依赖 | 成本 |
|------|---------|----------|----------|------|
| 小鹏 | Xavier | 视觉+毫米波 | 强依赖 | ~5000元 |
| 蔚来 | EyeQ4 | 纯视觉 | 中等依赖 | ~8000元 |
| 理想 | 征程3 | 视觉为主 | 轻依赖 | ~3000元 |

### 3.7.4 用户接受度与迭代

**使用数据**（2020年底）：
- 小鹏NGP：日均使用里程超过20万公里
- 蔚来NOP：累计行驶超过1000万公里
- 月度OTA更新成为常态

**快速迭代特点**：
- 2周一次的算法优化
- 基于用户反馈的功能改进
- 影子模式数据收集

## 3.8 感知技术栈的全面升级

### 3.8.1 2019-2020年的关键技术突破总结

```
技术演进时间线：
2019 Q1 ├─ Pseudo-LiDAR论文发表
2019 Q2 ├─ Tesla Autonomy Day
2019 Q3 ├─ 多任务学习网络普及
2019 Q4 ├─ 深度估计突破0.1误差
2020 Q1 ├─ 德国批准Autopilot
2020 Q2 ├─ COVID推动无人配送
2020 Q3 ├─ LSS/BEV方法提出
2020 Q4 ├─ 中国NOA大规模落地
```

### 3.8.2 产业格局变化

**算力军备竞赛开始**：
- 2019年：30-100 TOPS成为主流
- 2020年：100-200 TOPS成为新标准
- 预告2021年：500+ TOPS平台出现

**数据成为核心竞争力**：
- 数据闭环的重要性凸显
- 影子模式成为标配
- 自动标注技术快速发展

### 3.8.3 未来趋势预判（2020年底的视角）

1. **BEV将成为主流**：多家公司开始投入BEV研发
2. **Transformer即将到来**：NLP的成功预示CV变革
3. **端到端探索加速**：模块化的瓶颈日益明显
4. **中美技术路线分化**：特斯拉纯视觉 vs 中国融合路线

## 本章小结

2019-2020年是自动驾驶感知技术从量变到质变的关键时期。特斯拉通过垂直整合展示了算法与芯片协同设计的威力，多任务学习网络的兴起大幅提升了系统效率，伪激光雷达和深度估计的突破证明了纯视觉3D感知的可行性。COVID疫情意外加速了无人配送的落地，而BEV感知范式的出现预示着下一代技术变革。中国市场在这一时期快速崛起，本土NOA功能的落地标志着中国自动驾驶产业进入快速发展期。

这两年奠定的技术基础，为2021-2022年的BEV和Transformer革命铺平了道路，也预示着端到端学习时代的到来。

---

*下一章：[第4章 BEV与Transformer变革 (2021-2022)](chapter4.md)*